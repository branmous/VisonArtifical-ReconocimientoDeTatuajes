{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proceso de importación de Referencias\n",
    "\n",
    "\n",
    "# Siempre que usemos matplotlib en Jupyter es necesario poner esta línea antes de cualquier otra\n",
    "%matplotlib inline\n",
    "\n",
    "# Importamos las bibliotecas necesarias y les asignamos un alias\n",
    "import skimage                           # Biblioteca para la manipulación de imágenes\n",
    "import numpy as np                       # Biblioteca para la manipulación de matrices\n",
    "\n",
    "# Importamos algunos paquetes específicos\n",
    "from matplotlib import pyplot as plt     # Biblioteca para crear gráficas y mostrar las imágenes en pantalla\n",
    "\n",
    "from skimage import data                 # Paquete con imágenes de prueba\n",
    "from skimage import io                   # Paquete para lectura/escritura de imágenes\n",
    "from skimage import color                # Paquete con las operaciones de transformaciones entre espacios de color\n",
    "from skimage import exposure             # Paquete con las funciones para calcular y alterar el histograma\n",
    "from skimage import filters              # Paquete que contiene las máscaras y filtros de suavizado y realzado\n",
    "from skimage import util                 # Paquete que contiene las funciones para cambiar el tipo de dato de las imágenes\n",
    "from skimage import morphology           # Para crear el kernel de convolución en los filtros no lienales\n",
    "from skimage import transform            # Esta biblioteca es la que contiene la implementación de Hough\n",
    "from skimage import measure              # Esta biblioteca contiene el método de etiquetado de regiones\n",
    "from skimage import feature              # Esta biblioteca es la que contiene la implementación del canny\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "\n",
    "from scipy import ndimage                # Usamos esta biblioteca para realizar la operación de convolución\n",
    "import skdemo                            # Paquete ESPECIAL ADJUNTO con algunas funciones extra de visualización\n",
    "import os\n",
    "###########################\n",
    "\n",
    "from scipy.stats import kde              # Esta biblioteca es necesaria para estimar la función de densidad de los datos\n",
    "from sklearn import preprocessing        # Este paquete contiene las funciones de preprocesamiento de datos\n",
    "from sklearn import feature_selection    # Este paquete contiene los métodos de selección de características de sklearn\n",
    "from sklearn import svm                  # Este paquete contiene las funciones de un clasificador SVM\n",
    "from sklearn import model_selection      # Este paquete contiene las funciones de particionamiento de datos y validación cruzada\n",
    "from sklearn import metrics              # Este paquete contiene las funciones para evaluar un clasificador\n",
    "from sklearn import neighbors \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Con este nos aseguramos que las imágenes en niveles de gris, se vean como tal siempre.\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "\n",
    "sq = morphology.square(width=3)\n",
    "dia = morphology.diamond(radius=1)\n",
    "rd = morphology.disk(radius=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proceso individual de imagenes\n",
    "\n",
    "img_orginal = skimage.img_as_float(io.imread(\"imagenes/vannesa/v10.jpg\"))\n",
    "skdemo.imshow_all(img_orginal[..., 0], img_orginal[..., 1], img_orginal[..., 2],\n",
    "                 titles=['R', 'G', 'B'])\n",
    "\n",
    "\n",
    "img_3 = img_orginal[..., 0].copy()\n",
    "skdemo.imshow_with_histogram(img_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = morphology.square(10)\n",
    "img_median = filters.rank.median(img_3, k)\n",
    "skdemo.imshow_all(img_3,img_median)\n",
    "img_min = filters.rank.minimum(img_median, k)\n",
    "skdemo.imshow_all(img_3,img_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradiente = filters.sobel(img_min)\n",
    "imgfloat = skimage.img_as_float(gradiente)\n",
    "skdemo.imshow_with_histogram(imgfloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tatto = gradiente > 0.03\n",
    "plt.imshow(img_tatto, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dilatada = morphology.dilation(img_tatto, sq)\n",
    "skdemo.imshow_all(img_tatto, img_dilatada)\n",
    "#img_tatto = img_dilatada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiqueta = measure.label(img_dilatada)\n",
    "plt.imshow(etiqueta, cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = measure.regionprops(etiqueta)\n",
    "\n",
    "areas = [r.area for r in props]\n",
    "largest_ind = np.argmax(areas)\n",
    "\n",
    "x1= props[largest_ind].bbox[0]\n",
    "x2= props[largest_ind].bbox[2]\n",
    "y1= props[largest_ind].bbox[1]\n",
    "y2= props[largest_ind].bbox[3]\n",
    "\n",
    "\n",
    "img_cut = img_orginal[x1:x2,y1:y2].copy()\n",
    "\n",
    "#plt.imshow(img_cut, cmap='gray')\n",
    "skdemo.imshow_all(img_3,img_cut)\n",
    "\n",
    "\n",
    "etiqueta = measure.label(img_cut)\n",
    "print(\"img_cut\", etiqueta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imsave('imagenes/vannesa/v10.jpg', img_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = None;\n",
    "y = [];\n",
    "train_image = [];\n",
    "urls = [];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proceso para la base de datos\n",
    "\n",
    "#Metodo que segmenta cada imagen \n",
    "def segmentacionImage(img):    \n",
    "    img_1 = img.copy()\n",
    "    img_1 = img_1[..., 0]\n",
    "    k = morphology.square(10)\n",
    "    img_median = filters.rank.median(img_1, k)\n",
    "    img_min = filters.rank.minimum(img_median, k)\n",
    "    \n",
    "    gradiente = filters.sobel(img_min)\n",
    "    imgfloat = skimage.img_as_float(gradiente)\n",
    "    img_tatto = gradiente > 0.03        \n",
    "        \n",
    "    return img_1,img_tatto\n",
    "\n",
    "def createMatriz(array):\n",
    "    # f, axes = plt.subplots(ncols=4, nrows=len(array), figsize=(10, 30))   \n",
    "    for i,image in enumerate(array):\n",
    "        imageR,img_seg = segmentacionImage(image)       \n",
    "        img_dilatada = morphology.dilation(img_seg, sq)                \n",
    "        \n",
    "        f1 = measure.label(img_dilatada)\n",
    "        imgCut_cut = CutImage(image,f1)\n",
    "        imgCut = rgb2gray(imgCut_cut)   \n",
    "        imgCut = resize(imgCut, (200,200))\n",
    "\n",
    "        train_image.append(imgCut.reshape(-1));\n",
    "        \n",
    "        urls.append(os.path.relpath(array.files[i]));\n",
    "        y.append(os.path.dirname(array.files[i]))\n",
    "   \n",
    "   \n",
    "def CutImage(imgOri,img):\n",
    "    props = measure.regionprops(img)\n",
    "    areas = [r.area for r in props]\n",
    "    largest_ind = np.argmax(areas)\n",
    "\n",
    "    x1= props[largest_ind].bbox[0]\n",
    "    x2= props[largest_ind].bbox[2]\n",
    "    y1= props[largest_ind].bbox[1]\n",
    "    y2= props[largest_ind].bbox[3]\n",
    "\n",
    "\n",
    "    img_cut = imgOri[x1:x2,y1:y2].copy()\n",
    "    return img_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vannesaTattoos = io.ImageCollection('imagenes/vannesa/*.jpg')\n",
    "createMatriz(vannesaTattoos)\n",
    "\n",
    "carmelinaTattoos = io.ImageCollection('imagenes/carmelina/*.jpg')\n",
    "createMatriz(carmelinaTattoos)\n",
    "\n",
    "faustinoTattoos = io.ImageCollection('imagenes/faustino/*.jpg')\n",
    "createMatriz(faustinoTattoos)\n",
    "\n",
    "carlosTattoos = io.ImageCollection('imagenes/carlos/*.jpg')\n",
    "createMatriz(carlosTattoos)\n",
    "\n",
    "y = np.asarray(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_image)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10, test_size=0.20)\n",
    "\n",
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Primero definimos el clasificador y sus parámetros\n",
    "# En este caso estamos usando una distancia euclidiana y 2 vecinos\n",
    "clf_knn = neighbors.KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "\n",
    "# Después ajustamos el clasificador a los datos de entrenamiento (aprendemos de los datos)\n",
    "clf_knn.fit(X_train, y_train)\n",
    "\n",
    "# A continuación, usamos el clasificador entrenado para predecir la etiqueta de los datos de prueba\n",
    "y_predicted = clf_knn.predict(X_test)\n",
    "\n",
    "# Ahora podemos calcular y ver la precisión del clasificador\n",
    "acc = metrics.accuracy_score(y_test, y_predicted)\n",
    "mat = metrics.confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "\n",
    "print (\"Precisión del clasificador kNN: \",acc)\n",
    "print (\"Matriz de Confusión: \\n\", mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 3\n",
    "X_t = np.reshape(X_test[index], (-1, 200))\n",
    "\n",
    "imgplot = plt.imshow(X_t)  \n",
    "plt.show()  \n",
    "print('predicted:         ' + str(y_predicted[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
